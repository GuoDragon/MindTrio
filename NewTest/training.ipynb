{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-cell",
   "metadata": {},
   "source": [
    "# 中文篇章级句间关系分类 - LoRA微调实验\n",
    "\n",
    "## 实验说明\n",
    "\n",
    "本实验使用 **MindSpore + mindnlp 0.5.1 + LoRA** 在 **DeepSeek-R1-Distill-Qwen-1.5B** 模型上进行微调。\n",
    "\n",
    "### 任务目标\n",
    "- **输入**：一个句子或对话片段\n",
    "- **输出**：该句子所属的PDTB篇章关系分类（扩展/因果/比较/并列/其他）以及分类原因\n",
    "\n",
    "### 版本信息\n",
    "- mindnlp: 0.5.1(显示 0.5.0rc2 为源码编译问题)\n",
    "- mindspore: 2.7.0\n",
    "- transformers: 4.47.1\n",
    "- 数据类型: bfloat16\n",
    "\n",
    "### 训练环境\n",
    "- 镜像：ms2.7.1-cann8.2rc1（名称）、v3（版本）、mindspore courses（所属组织）\n",
    "- 实例规格：Ascend: 1*ascend-snt9b1 | ARM: 24核 192GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-cell-header",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "import-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/work/lcl/lib/python3.10/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/work/lcl/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/work/lcl/lib/python3.10/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ma-user/work/lcl/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ma-user/work/lcl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Modular Diffusers is currently an experimental feature under active development. The API is subject to breaking changes in future releases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindnlp版本: 0.5.0rc2\n",
      "mindspore版本: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "# 核心框架\n",
    "import mindnlp\n",
    "import mindspore\n",
    "\n",
    "# 数据处理\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# 模型和训练相关\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# LoRA相关\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "# 查看版本信息\n",
    "print(f\"mindnlp版本: {mindnlp.__version__}\")\n",
    "print(f\"mindspore版本: {mindspore.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-load-header",
   "metadata": {},
   "source": [
    "## 2. 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "data-load-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集样本数: 9198\n",
      "验证集样本数: 1500\n",
      "\n",
      "数据集前3个样本:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'content': ['他的有没有什么不足之处？我觉得他可以就是加一些他自己的感受，因为他如果光只说那些一系列的动作，就感觉很空白，没有什么情感在里面。',\n",
       "  '星汉是什么？银河。',\n",
       "  '对于花来说没有人欣赏是多么的悲惨，就像我们姑娘把自己打扮得花枝招展，却没有人欣赏一样是一种不幸'],\n",
       " 'summary': ['扩展\\n原因：前半句话提出问题，询问他的不足之处，后半句话则具体回答了我认为的他的不足之处，所以属于扩展关系。',\n",
       "  '扩展\\n原因：',\n",
       "  '扩展\\n原因：']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据路径\n",
    "train_path = \"/home/ma-user/work/data/train.json\"\n",
    "val_path = \"/home/ma-user/work/data/val.json\"\n",
    "\n",
    "# 读取数据\n",
    "df_train = pd.read_json(train_path)\n",
    "df_val = pd.read_json(val_path)\n",
    "\n",
    "# 转换为Dataset格式\n",
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_val = Dataset.from_pandas(df_val)\n",
    "\n",
    "# 查看数据集信息\n",
    "print(f\"训练集样本数: {len(ds_train)}\")\n",
    "print(f\"验证集样本数: {len(ds_val)}\")\n",
    "print(\"\\n数据集前3个样本:\")\n",
    "ds_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tokenizer-header",
   "metadata": {},
   "source": [
    "## 3. 加载Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tokenizer-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表大小: 151643\n",
      "最大长度: 16384\n",
      "PAD token: <｜end▁of▁sentence｜>\n",
      "EOS token: <｜end▁of▁sentence｜>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', vocab_size=151643, model_max_length=16384, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<｜begin▁of▁sentence｜>', 'eos_token': '<｜end▁of▁sentence｜>', 'pad_token': '<｜end▁of▁sentence｜>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<｜end▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<｜User｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151645: AddedToken(\"<｜Assistant｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151646: AddedToken(\"<｜begin▁of▁sentence｜>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|EOT|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151648: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151649: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载tokenizer\n",
    "model_name = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name, \n",
    "    use_fast=False, \n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 查看tokenizer信息\n",
    "print(f\"词汇表大小: {tokenizer.vocab_size}\")\n",
    "print(f\"最大长度: {tokenizer.model_max_length}\")\n",
    "print(f\"PAD token: {tokenizer.pad_token}\")\n",
    "print(f\"EOS token: {tokenizer.eos_token}\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-header",
   "metadata": {},
   "source": [
    "## 4. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "preprocess-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理训练集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9198/9198 [00:07<00:00, 1275.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集处理完成！\n",
      "\n",
      "开始处理验证集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1500/1500 [00:01<00:00, 1455.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集处理完成！\n",
      "\n",
      "处理后的第一个样本解码结果:\n",
      "<|im_start|>system\n",
      "你是一位PDTB中文文本关系分析助手<|im_end|>\n",
      "<|im_start|>user\n",
      "他的有没有什么不足之处？我觉得他可以就是加一些他自己的感受，因为他如果光只说那些一系列的动作，就感觉很空白，没有什么情感在里面。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "扩展\n",
      "原因：前半句话提出问题，询问他的不足之处，后半句话则具体回答了我认为的他的不足之处，所以属于扩展关系。<｜end▁of▁sentence｜>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 最大序列长度\n",
    "MAX_LENGTH = 1024\n",
    "\n",
    "def process_func(example):\n",
    "    # 构建指令部分\n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\n你是一位PDTB中文文本关系分析助手<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{example.get('content', '') + example.get('input', '')}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    \n",
    "    # 构建回答部分\n",
    "    response = tokenizer(\n",
    "        f\"{example.get('summary', '')}\", \n",
    "        add_special_tokens=False\n",
    "    )\n",
    "\n",
    "    # 拼接 input_ids 和 attention_mask\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    \n",
    "    # 构建 labels：指令部分设为 -100（不计算损失），只对回答部分计算损失\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "\n",
    "    # 截断到最大长度\n",
    "    input_ids = input_ids[:MAX_LENGTH]\n",
    "    attention_mask = attention_mask[:MAX_LENGTH]\n",
    "    labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids, \n",
    "        \"attention_mask\": attention_mask, \n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# 处理训练集和验证集\n",
    "print(\"开始处理训练集...\")\n",
    "tokenized_train = ds_train.map(process_func, remove_columns=ds_train.column_names)\n",
    "print(\"训练集处理完成！\")\n",
    "\n",
    "print(\"\\n开始处理验证集...\")\n",
    "tokenized_val = ds_val.map(process_func, remove_columns=ds_val.column_names)\n",
    "print(\"验证集处理完成！\")\n",
    "\n",
    "# 查看处理后的第一个样本\n",
    "print(\"\\n处理后的第一个样本解码结果:\")\n",
    "print(tokenizer.decode(tokenized_train[0]['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-load-header",
   "metadata": {},
   "source": [
    "## 5. 加载基础模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "model-load-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型，请稍候...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB\n",
      "模型加载完成！\n",
      "模型参数量: 1,777,088,000\n"
     ]
    }
   ],
   "source": [
    "# 加载基础模型\n",
    "print(\"正在加载模型，请稍候...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    ms_dtype=mindspore.bfloat16,  # 使用bfloat16数据类型\n",
    "    device_map=0  # 指定设备\n",
    ")\n",
    "\n",
    "# 开启梯度计算\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "print(\"模型加载完成！\")\n",
    "print(f\"模型参数量: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lora-config-header",
   "metadata": {},
   "source": [
    "## 6. 配置LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lora-config-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,464,768 || all params: 1,795,552,768 || trainable%: 1.0284\n"
     ]
    }
   ],
   "source": [
    "# 配置LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  # 因果语言模型\n",
    "    target_modules=[        # 要应用LoRA的模块（注意力层和FFN层）\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",   # 注意力层\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"       # FFN层\n",
    "    ],\n",
    "    r=16,                   # LoRA秩\n",
    "    lora_alpha=32,          # LoRA缩放因子\n",
    "    lora_dropout=0.05,      # Dropout率\n",
    "    inference_mode=False    # 训练模式\n",
    ")\n",
    "\n",
    "# 应用LoRA到模型\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 打印可训练参数信息\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-args-header",
   "metadata": {},
   "source": [
    "## 7. 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "training-args-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练参数配置完成！\n",
      "有效batch size: 20\n",
      "总训练步数: 1377\n"
     ]
    }
   ],
   "source": [
    "# 定义训练参数\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output\",                    # 输出目录\n",
    "    per_device_train_batch_size=4,            # batch size\n",
    "    gradient_accumulation_steps=5,            # 梯度累积步数\n",
    "    logging_steps=10,                         # 日志记录间隔\n",
    "    num_train_epochs=3,                       # 训练轮数\n",
    "    save_steps=100,                           # checkpoint保存间隔\n",
    "    learning_rate=3e-5,                       # 学习率\n",
    "    save_on_each_node=True,                   # 在每个节点上保存\n",
    ")\n",
    "\n",
    "print(\"训练参数配置完成！\")\n",
    "print(f\"有效batch size: {args.per_device_train_batch_size * args.gradient_accumulation_steps}\")\n",
    "print(f\"总训练步数: {len(tokenized_train) // (args.per_device_train_batch_size * args.gradient_accumulation_steps) * args.num_train_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trainer-header",
   "metadata": {},
   "source": [
    "## 8. 创建Trainer并开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trainer-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.19.90, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer创建成功！\n"
     ]
    }
   ],
   "source": [
    "# 创建Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    ")\n",
    "\n",
    "print(\"Trainer创建成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 开始训练 ==========\n",
      "预计训练时间: 约1.5-2小时（基于之前的训练经验）\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='358' max='1380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 358/1380 22:44 < 1:05:16, 0.26 it/s, Epoch 0.78/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.547900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.537700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.483600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.875100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.325900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.184500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.158600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.125200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.969200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.962900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.987700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.909200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.044400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.884900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.956500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 开始训练\n",
    "print(\"========== 开始训练 ==========\")\n",
    "print(\"预计训练时间: 约1.5-2小时（基于之前的训练经验）\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 9. 训练总结\n",
    "\n",
    "训练完成后：\n",
    "- LoRA权重保存在 `./output/checkpoint-xxxx/` 目录中\n",
    "- 主要文件包括：\n",
    "  - `adapter_model.safetensors`: LoRA适配器权重\n",
    "  - `adapter_config.json`: LoRA配置\n",
    "  - `trainer_state.json`: 训练状态\n",
    "\n",
    "### 下一步\n",
    "使用 `merge.ipynb` 脚本将LoRA权重与基础模型合并，或直接使用checkpoint进行推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看训练结果文件\n",
    "import os\n",
    "print(\"训练输出目录内容:\")\n",
    "if os.path.exists('./output'):\n",
    "    for item in os.listdir('./output'):\n",
    "        print(f\"  - {item}\")\n",
    "else:\n",
    "    print(\"输出目录尚未创建\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lcl)",
   "language": "python",
   "name": "lcl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
