{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feecebb1-e6f9-4600-a481-b9e6ec334e76",
   "metadata": {},
   "source": [
    "# PDTB 句间关系分类 LoRA 模型合并\n",
    "本脚本用于将 LoRA 微调后的权重与基础模型合并，并进行推理测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c44dfa-d302-4711-a822-9df3d84c58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindnlp\n",
    "import mindspore\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, GenerationConfig\n",
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "\n",
    "# 检查mindnlp版本\n",
    "print(\"MindNLP版本:\", mindnlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bef02-4500-4438-9cfd-5c33e5ee6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', use_fast=False, trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035c183-f1e7-4f33-809d-e5ff933ed3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',\n",
    "    ms_dtype=mindspore.bfloat16,\n",
    "    device_map=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b15c02-84ab-4653-814f-86a415ec6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练好的 checkpoint 路径\n",
    "# 注意：这里需要修改为实际的checkpoint路径\n",
    "lora_path = \"./output/checkpoint-1380\"\n",
    "\n",
    "# 保存合并后模型的目录\n",
    "merged_path = \"./merged_qwen_lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c7565-6c53-4394-b9e6-47ed49c9ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 LoRA 权重\n",
    "model = PeftModel.from_pretrained(model, lora_path)\n",
    "\n",
    "# 合并权重\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# 保存最终模型\n",
    "model.save_pretrained(merged_path)\n",
    "tokenizer.save_pretrained(merged_path)\n",
    "\n",
    "print(f\"LoRA 权重已合并完成，模型保存在: {merged_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a947b-580c-4502-a053-cbb3149621e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理测试\n",
    "# 重新加载合并后的模型\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_path,\n",
    "    ms_dtype=mindspore.bfloat16,\n",
    "    device_map=0\n",
    ")\n",
    "\n",
    "# 测试样本\n",
    "test_samples = [\n",
    "    \"月亮又圆又亮，所以古人称之为玉盘。\",\n",
    "    \"他的有没有什么不足之处？我觉得他可以就是加一些他自己的感受，因为他如果光只说那些一系列的动作，就感觉很空白，没有什么情感在里面。\",\n",
    "    \"星汉是什么？银河。\"\n",
    "]\n",
    "\n",
    "for sample in test_samples:\n",
    "    print(\"\\n输入:\", sample)\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template([\n",
    "        {\"role\": \"system\", \"content\": \"你是一个中文篇章句间关系分析师\"},\n",
    "        {\"role\": \"user\", \"content\": sample}\n",
    "    ], add_generation_prompt=True, tokenize=True, return_tensors=\"ms\", return_dict=True)\n",
    "    \n",
    "    gen_kwargs = {\"max_length\": 200, \"do_sample\": True, \"top_k\": 1}\n",
    "    with mindspore.no_grad():\n",
    "        outputs = merged_model.generate(**inputs, **gen_kwargs)\n",
    "        outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "        result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(\"输出:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
