{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feecebb1-e6f9-4600-a481-b9e6ec334e76",
   "metadata": {},
   "source": [
    "# PDTB 句间关系分类 LoRA 微调实验\n",
    "本实验使用 `MindSpore + mindnlp + LoRA` 在 `DeepSeek-R1-Distill-Qwen-1.5B` 模型上进行微调，任务目标是：\n",
    "- 输入：一个句子（或对话内容）\n",
    "- 输出：该句子属于哪一种 PDTB 分类，并解释原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c44dfa-d302-4711-a822-9df3d84c58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindnlp\n",
    "import mindspore\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer, GenerationConfig\n",
    "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
    "\n",
    "# 检查mindnlp版本\n",
    "print(\"MindNLP版本:\", mindnlp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fbe5ea-e77a-4d8f-a6a3-6cea49cdc191",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/home/ma-user/work/data/train.json\"\n",
    "val_path = \"/home/ma-user/work/data/val.json\"\n",
    "\n",
    "df_train = pd.read_json(train_path)\n",
    "df_val = pd.read_json(val_path)\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train)\n",
    "ds_val = Dataset.from_pandas(df_val)\n",
    "\n",
    "ds_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bef02-4500-4438-9cfd-5c33e5ee6509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B', use_fast=False, trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8783b07-d522-4718-9447-67a493b37d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 384\n",
    "\n",
    "def process_func(example):\n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\n你是PDTB文本关系分析助手<|im_end|>\\n\"\n",
    "        f\"<|im_start|>user\\n{example.get('content','') + example.get('input','')}<|im_end|>\\n\"\n",
    "        f\"<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    response = tokenizer(f\"{example.get('summary','')}\", add_special_tokens=False)\n",
    "\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "\n",
    "    # 截断\n",
    "    input_ids = input_ids[:MAX_LENGTH]\n",
    "    attention_mask = attention_mask[:MAX_LENGTH]\n",
    "    labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "tokenized_train = ds_train.map(process_func, remove_columns=ds_train.column_names)\n",
    "tokenized_train\n",
    "\n",
    "tokenized_val = ds_val.map(process_func, remove_columns=ds_val.column_names)\n",
    "tokenized_val\n",
    "\n",
    "tokenizer.decode(tokenized_train[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a035c183-f1e7-4f33-809d-e5ff933ed3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B',\n",
    "    ms_dtype=mindspore.bfloat16,\n",
    "    device_map=0\n",
    ")\n",
    "\n",
    "# 开启梯度检查点\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25443063-21dc-40c0-ab42-4f5a9d044ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd24538b-5266-4d62-b159-bdcce69277bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练超参数\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=5,\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100, \n",
    "    learning_rate=3e-5,\n",
    "    save_on_each_node=True,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e1474-e9c8-4d37-a5bd-b00340e2b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_train,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    eval_dataset=tokenized_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb50058-e97d-494d-9243-77266e49d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "train_result = trainer.train()\n",
    "print(\"训练结果:\", train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c7565-6c53-4394-b9e6-47ed49c9ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最终模型\n",
    "model.save_pretrained(\"./output/final_model\")\n",
    "tokenizer.save_pretrained(\"./output/final_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
