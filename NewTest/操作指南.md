# MindSpore LoRA微调 DeepSeek-R1-Distill-Qwen-1.5B 操作指南

本指南旨在解决在华为云ModelArts Notebook中运行中文篇章级句间关系分析任务时，`trainer.train()` 卡死的问题。

## 1. 前提条件

*   已在华为云ModelArts中创建Notebook，并选择镜像：`mindspore_2_7-vllm-mindspeed-cann8_2alpha2_ubuntu22（名称）、ma20250630（版本）、mindspore0904（所属组织）`。
*   实例规格为：`Ascend: 1*ascend-snt9b1 | ARM: 24核 192GB`。
*   已创建并激活Python虚拟环境 `lcl`，并安装 Jupyter 内核。
*   已成功安装 `mindnlp==0.5.1`。
*   确保数据集 `train.json` 和 `val.json` 已上传至 `/home/ma-user/work/data/` 目录。

## 2. 确认 `transformers` 库版本

根据您之前的成功运行经验，`transformers==4.57.1` 版本是您能够运行到 `trainer.train()` 阶段的版本。

在ModelArts Notebook的终端中（或通过Notebook中的代码单元格执行），运行以下命令确认 `transformers` 版本：

```bash
pip show transformers
```

如果版本不是 `4.57.1`，请按照以下步骤调整：

1.  **卸载现有 `transformers` 库：**

    ```bash
    pip uninstall transformers -y
    ```

2.  **安装指定版本 `transformers` 库：**

    ```bash
    pip install transformers==4.57.1 -i https://pypi.tuna.tsinghua.edu.cn/simple
    ```

    *注意：根据您的环境，可能需要指定清华源或华为云镜像源以加快下载速度，例如：`pip install transformers==4.57.1 -i https://pypi.tuna.tsinghua.edu.cn/simple`*

## 3. 运行 `training.ipynb` 进行训练

在确认 `transformers` 版本无误后，您可以在ModelArts Notebook中打开并运行 `D:\lcl\MindSpore_CCNU_MindTrio\NewTest\training.ipynb` 文件。按照Notebook中的步骤执行各个代码单元格。

预计 `trainer.train()` 方法将能够顺利执行。

## 4. 训练总结与下一步

训练完成后，LoRA权重将保存在 `./output/checkpoint-xxxx/` 目录中。您可以使用 `merge.ipynb` 脚本将LoRA权重与基础模型合并，或直接使用checkpoint进行推理。

**请注意：** 如果在执行过程中遇到新的问题，请提供详细的错误信息和日志，以便进一步分析和解决。