# 任务定义
我正在进行中文篇章级句间关系分析任务，目的是通过采用MindSpore框架LoRA微调DeepSeek-R1-Distill-Qwen-1.5B大模型

# 任务背景
1. 我之前在今年8月份的时候已经跑过全流程了，相关文件和结果在`D:\hw\旧实验`中存有备份，相关最佳的微调结果权重在`D:\hw\checkpoint-1380`中有备份
2. 所有相关实验都在华为云ModelArts中的Nootbook中进行，选择的镜像是**mindspore_2_7-vllm-mindspeed-cann8_2alpha2_ubuntu22（名称）、ma20250630（版本）、mindspore0904（所属组织）**，实例规格为**Ascend: 1*ascend-snt9b1|ARM: 24核 192GB**
3. 之前华为昇思老师的宣讲材料在`D:\hw\资料手册`中，可以作为一定的参考资料
4. 但是现在随着版本更新，完全按照之前的版本已经跑不通了
5. 用中文回答我

# 当前任务
1. 请你结合之前的微调脚本，和当前的最新版本**mindnlp0.5.1**，来完成最新的正确运行版本
2. 生成的相关内容存放在`D:\hw\NewTest`中
3. 最好使用 ipynb 格式，便于调试
4. 同步生成指南文件，告诉我该如何操作